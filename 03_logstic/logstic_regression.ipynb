{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "num_epoches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Logstic_Regression(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Logstic_Regression, self).__init__()\n",
    "        self.logstic = nn.Linear(in_dim, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.logstic(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "use_gpu = torch.cuda.is_available()  # 判断是否有GPU加速\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Logstic_Regression(28 * 28, 10)  # 图片大小是28x28\n",
    "\n",
    "model = model.cuda()\n",
    "# 定义loss和optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Logstic_Regression (\n",
       "  (logstic): Linear (784 -> 10)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "epoch 1\n",
      "[1/100] Loss: 2.157034, Acc: 0.346875\n",
      "[1/100] Loss: 2.028956, Acc: 0.503073\n",
      "[1/100] Loss: 1.915679, Acc: 0.578715\n",
      "[1/100] Loss: 1.818451, Acc: 0.624349\n",
      "[1/100] Loss: 1.734924, Acc: 0.654333\n",
      "[1/100] Loss: 1.662632, Acc: 0.675816\n",
      "Finish 1 epoch, Loss: 1.645766, Acc: 0.680667\n",
      "**********\n",
      "epoch 2\n",
      "[2/100] Loss: 1.186911, Acc: 0.795729\n",
      "[2/100] Loss: 1.154649, Acc: 0.803438\n",
      "[2/100] Loss: 1.124006, Acc: 0.806354\n",
      "[2/100] Loss: 1.091885, Acc: 0.811354\n",
      "[2/100] Loss: 1.069460, Acc: 0.812438\n",
      "[2/100] Loss: 1.047444, Acc: 0.813785\n",
      "Finish 2 epoch, Loss: 1.042387, Acc: 0.814367\n",
      "**********\n",
      "epoch 3\n",
      "[3/100] Loss: 0.888929, Acc: 0.828333\n",
      "[3/100] Loss: 0.878783, Acc: 0.829323\n",
      "[3/100] Loss: 0.867213, Acc: 0.831389\n",
      "[3/100] Loss: 0.855118, Acc: 0.833125\n",
      "[3/100] Loss: 0.841919, Acc: 0.834708\n",
      "[3/100] Loss: 0.830333, Acc: 0.837066\n",
      "Finish 3 epoch, Loss: 0.827293, Acc: 0.837383\n",
      "**********\n",
      "epoch 4\n",
      "[4/100] Loss: 0.756148, Acc: 0.842292\n",
      "[4/100] Loss: 0.746246, Acc: 0.845833\n",
      "[4/100] Loss: 0.738354, Acc: 0.847778\n",
      "[4/100] Loss: 0.731914, Acc: 0.847240\n",
      "[4/100] Loss: 0.725229, Acc: 0.846958\n",
      "[4/100] Loss: 0.719330, Acc: 0.847604\n",
      "Finish 4 epoch, Loss: 0.718196, Acc: 0.847650\n",
      "**********\n",
      "epoch 5\n",
      "[5/100] Loss: 0.670264, Acc: 0.853854\n",
      "[5/100] Loss: 0.666312, Acc: 0.853281\n",
      "[5/100] Loss: 0.663656, Acc: 0.853576\n",
      "[5/100] Loss: 0.661705, Acc: 0.854167\n",
      "[5/100] Loss: 0.656272, Acc: 0.855458\n",
      "[5/100] Loss: 0.652727, Acc: 0.855313\n",
      "Finish 5 epoch, Loss: 0.651120, Acc: 0.855567\n",
      "**********\n",
      "epoch 6\n",
      "[6/100] Loss: 0.614924, Acc: 0.861979\n",
      "[6/100] Loss: 0.615993, Acc: 0.860104\n",
      "[6/100] Loss: 0.617059, Acc: 0.859722\n",
      "[6/100] Loss: 0.612184, Acc: 0.860026\n",
      "[6/100] Loss: 0.612526, Acc: 0.859542\n",
      "[6/100] Loss: 0.607244, Acc: 0.860573\n",
      "Finish 6 epoch, Loss: 0.605157, Acc: 0.861133\n",
      "**********\n",
      "epoch 7\n",
      "[7/100] Loss: 0.580548, Acc: 0.866458\n",
      "[7/100] Loss: 0.583153, Acc: 0.863542\n",
      "[7/100] Loss: 0.580515, Acc: 0.863750\n",
      "[7/100] Loss: 0.573530, Acc: 0.865495\n",
      "[7/100] Loss: 0.572352, Acc: 0.865938\n",
      "[7/100] Loss: 0.571737, Acc: 0.865347\n",
      "Finish 7 epoch, Loss: 0.571368, Acc: 0.865133\n",
      "**********\n",
      "epoch 8\n",
      "[8/100] Loss: 0.562896, Acc: 0.862396\n",
      "[8/100] Loss: 0.555569, Acc: 0.865104\n",
      "[8/100] Loss: 0.550138, Acc: 0.867708\n",
      "[8/100] Loss: 0.551924, Acc: 0.866354\n",
      "[8/100] Loss: 0.548317, Acc: 0.867583\n",
      "[8/100] Loss: 0.544937, Acc: 0.868507\n",
      "Finish 8 epoch, Loss: 0.545264, Acc: 0.868467\n",
      "**********\n",
      "epoch 9\n",
      "[9/100] Loss: 0.530806, Acc: 0.872083\n",
      "[9/100] Loss: 0.529481, Acc: 0.871406\n",
      "[9/100] Loss: 0.527300, Acc: 0.871736\n",
      "[9/100] Loss: 0.527601, Acc: 0.871016\n",
      "[9/100] Loss: 0.523825, Acc: 0.871792\n",
      "[9/100] Loss: 0.524348, Acc: 0.871649\n",
      "Finish 9 epoch, Loss: 0.524398, Acc: 0.871667\n",
      "**********\n",
      "epoch 10\n",
      "[10/100] Loss: 0.512065, Acc: 0.875417\n",
      "[10/100] Loss: 0.512942, Acc: 0.872135\n",
      "[10/100] Loss: 0.512446, Acc: 0.871979\n",
      "[10/100] Loss: 0.509922, Acc: 0.873177\n",
      "[10/100] Loss: 0.508152, Acc: 0.874208\n",
      "[10/100] Loss: 0.508112, Acc: 0.874253\n",
      "Finish 10 epoch, Loss: 0.507223, Acc: 0.874183\n",
      "**********\n",
      "epoch 11\n",
      "[11/100] Loss: 0.502254, Acc: 0.878854\n",
      "[11/100] Loss: 0.498271, Acc: 0.876719\n",
      "[11/100] Loss: 0.498837, Acc: 0.874861\n",
      "[11/100] Loss: 0.494831, Acc: 0.876042\n",
      "[11/100] Loss: 0.492532, Acc: 0.877000\n",
      "[11/100] Loss: 0.492872, Acc: 0.876840\n",
      "Finish 11 epoch, Loss: 0.492784, Acc: 0.876683\n",
      "**********\n",
      "epoch 12\n",
      "[12/100] Loss: 0.503303, Acc: 0.869479\n",
      "[12/100] Loss: 0.488337, Acc: 0.876354\n",
      "[12/100] Loss: 0.484604, Acc: 0.877222\n",
      "[12/100] Loss: 0.484945, Acc: 0.876536\n",
      "[12/100] Loss: 0.481810, Acc: 0.878333\n",
      "[12/100] Loss: 0.481986, Acc: 0.877899\n",
      "Finish 12 epoch, Loss: 0.480464, Acc: 0.878450\n",
      "**********\n",
      "epoch 13\n",
      "[13/100] Loss: 0.483199, Acc: 0.873125\n",
      "[13/100] Loss: 0.474595, Acc: 0.877240\n",
      "[13/100] Loss: 0.472808, Acc: 0.878403\n",
      "[13/100] Loss: 0.470689, Acc: 0.879036\n",
      "[13/100] Loss: 0.471418, Acc: 0.879271\n",
      "[13/100] Loss: 0.469511, Acc: 0.880330\n",
      "Finish 13 epoch, Loss: 0.469796, Acc: 0.880167\n",
      "**********\n",
      "epoch 14\n",
      "[14/100] Loss: 0.454280, Acc: 0.885208\n",
      "[14/100] Loss: 0.458198, Acc: 0.883177\n",
      "[14/100] Loss: 0.456656, Acc: 0.882604\n",
      "[14/100] Loss: 0.459444, Acc: 0.881458\n",
      "[14/100] Loss: 0.461051, Acc: 0.881375\n",
      "[14/100] Loss: 0.459140, Acc: 0.882222\n",
      "Finish 14 epoch, Loss: 0.460388, Acc: 0.881600\n",
      "**********\n",
      "epoch 15\n",
      "[15/100] Loss: 0.456515, Acc: 0.883229\n",
      "[15/100] Loss: 0.454793, Acc: 0.883802\n",
      "[15/100] Loss: 0.455718, Acc: 0.883299\n",
      "[15/100] Loss: 0.454928, Acc: 0.882474\n",
      "[15/100] Loss: 0.454843, Acc: 0.882792\n",
      "[15/100] Loss: 0.452635, Acc: 0.882674\n",
      "Finish 15 epoch, Loss: 0.452082, Acc: 0.882917\n",
      "**********\n",
      "epoch 16\n",
      "[16/100] Loss: 0.435713, Acc: 0.889062\n",
      "[16/100] Loss: 0.446437, Acc: 0.883802\n",
      "[16/100] Loss: 0.442432, Acc: 0.885312\n",
      "[16/100] Loss: 0.443688, Acc: 0.885182\n",
      "[16/100] Loss: 0.444330, Acc: 0.884813\n",
      "[16/100] Loss: 0.444759, Acc: 0.884323\n",
      "Finish 16 epoch, Loss: 0.444635, Acc: 0.884300\n",
      "**********\n",
      "epoch 17\n",
      "[17/100] Loss: 0.446806, Acc: 0.883125\n",
      "[17/100] Loss: 0.441381, Acc: 0.884479\n",
      "[17/100] Loss: 0.437454, Acc: 0.886597\n",
      "[17/100] Loss: 0.437632, Acc: 0.886667\n",
      "[17/100] Loss: 0.437472, Acc: 0.885708\n",
      "[17/100] Loss: 0.436901, Acc: 0.885712\n",
      "Finish 17 epoch, Loss: 0.437917, Acc: 0.885383\n",
      "**********\n",
      "epoch 18\n",
      "[18/100] Loss: 0.433090, Acc: 0.886563\n",
      "[18/100] Loss: 0.438249, Acc: 0.884844\n",
      "[18/100] Loss: 0.433551, Acc: 0.886458\n",
      "[18/100] Loss: 0.432950, Acc: 0.886432\n",
      "[18/100] Loss: 0.432711, Acc: 0.886687\n",
      "[18/100] Loss: 0.432186, Acc: 0.886649\n",
      "Finish 18 epoch, Loss: 0.431830, Acc: 0.886717\n",
      "**********\n",
      "epoch 19\n",
      "[19/100] Loss: 0.422213, Acc: 0.889167\n",
      "[19/100] Loss: 0.431554, Acc: 0.886146\n",
      "[19/100] Loss: 0.427963, Acc: 0.887326\n",
      "[19/100] Loss: 0.425922, Acc: 0.887995\n",
      "[19/100] Loss: 0.425616, Acc: 0.887646\n",
      "[19/100] Loss: 0.425421, Acc: 0.888021\n",
      "Finish 19 epoch, Loss: 0.426275, Acc: 0.887800\n",
      "**********\n",
      "epoch 20\n",
      "[20/100] Loss: 0.421012, Acc: 0.885938\n",
      "[20/100] Loss: 0.419883, Acc: 0.888698\n",
      "[20/100] Loss: 0.420188, Acc: 0.888229\n",
      "[20/100] Loss: 0.418262, Acc: 0.889479\n",
      "[20/100] Loss: 0.419145, Acc: 0.889062\n",
      "[20/100] Loss: 0.420970, Acc: 0.888646\n",
      "Finish 20 epoch, Loss: 0.421179, Acc: 0.888750\n",
      "**********\n",
      "epoch 21\n",
      "[21/100] Loss: 0.428079, Acc: 0.886146\n",
      "[21/100] Loss: 0.421301, Acc: 0.888437\n",
      "[21/100] Loss: 0.418166, Acc: 0.889028\n",
      "[21/100] Loss: 0.414917, Acc: 0.890156\n",
      "[21/100] Loss: 0.416077, Acc: 0.889708\n",
      "[21/100] Loss: 0.416616, Acc: 0.889236\n",
      "Finish 21 epoch, Loss: 0.416457, Acc: 0.889683\n",
      "**********\n",
      "epoch 22\n",
      "[22/100] Loss: 0.416097, Acc: 0.890208\n",
      "[22/100] Loss: 0.412545, Acc: 0.889792\n",
      "[22/100] Loss: 0.413585, Acc: 0.890174\n",
      "[22/100] Loss: 0.411877, Acc: 0.890339\n",
      "[22/100] Loss: 0.411359, Acc: 0.890979\n",
      "[22/100] Loss: 0.411463, Acc: 0.890642\n",
      "Finish 22 epoch, Loss: 0.412123, Acc: 0.890300\n",
      "**********\n",
      "epoch 23\n",
      "[23/100] Loss: 0.411399, Acc: 0.888646\n",
      "[23/100] Loss: 0.412867, Acc: 0.888646\n",
      "[23/100] Loss: 0.415118, Acc: 0.887708\n",
      "[23/100] Loss: 0.413402, Acc: 0.888724\n",
      "[23/100] Loss: 0.411635, Acc: 0.889958\n",
      "[23/100] Loss: 0.408813, Acc: 0.890712\n",
      "Finish 23 epoch, Loss: 0.408038, Acc: 0.891083\n",
      "**********\n",
      "epoch 24\n",
      "[24/100] Loss: 0.404308, Acc: 0.894167\n",
      "[24/100] Loss: 0.407548, Acc: 0.892083\n",
      "[24/100] Loss: 0.409873, Acc: 0.890521\n",
      "[24/100] Loss: 0.408012, Acc: 0.890807\n",
      "[24/100] Loss: 0.404774, Acc: 0.891625\n",
      "[24/100] Loss: 0.404360, Acc: 0.891649\n",
      "Finish 24 epoch, Loss: 0.404301, Acc: 0.891950\n",
      "**********\n",
      "epoch 25\n",
      "[25/100] Loss: 0.403303, Acc: 0.893646\n",
      "[25/100] Loss: 0.409833, Acc: 0.889271\n",
      "[25/100] Loss: 0.405589, Acc: 0.890417\n",
      "[25/100] Loss: 0.404577, Acc: 0.891224\n",
      "[25/100] Loss: 0.402764, Acc: 0.891479\n",
      "[25/100] Loss: 0.401223, Acc: 0.892014\n",
      "Finish 25 epoch, Loss: 0.400752, Acc: 0.892400\n",
      "**********\n",
      "epoch 26\n",
      "[26/100] Loss: 0.403298, Acc: 0.891458\n",
      "[26/100] Loss: 0.399991, Acc: 0.892500\n",
      "[26/100] Loss: 0.404131, Acc: 0.891215\n",
      "[26/100] Loss: 0.401262, Acc: 0.892057\n",
      "[26/100] Loss: 0.399161, Acc: 0.892583\n",
      "[26/100] Loss: 0.397749, Acc: 0.893212\n",
      "Finish 26 epoch, Loss: 0.397447, Acc: 0.893117\n",
      "**********\n",
      "epoch 27\n",
      "[27/100] Loss: 0.396243, Acc: 0.895208\n",
      "[27/100] Loss: 0.398426, Acc: 0.894583\n",
      "[27/100] Loss: 0.398550, Acc: 0.893576\n",
      "[27/100] Loss: 0.399248, Acc: 0.892682\n",
      "[27/100] Loss: 0.396619, Acc: 0.893229\n",
      "[27/100] Loss: 0.394746, Acc: 0.893715\n",
      "Finish 27 epoch, Loss: 0.394318, Acc: 0.893817\n",
      "**********\n",
      "epoch 28\n",
      "[28/100] Loss: 0.407506, Acc: 0.891354\n",
      "[28/100] Loss: 0.396759, Acc: 0.892917\n",
      "[28/100] Loss: 0.393824, Acc: 0.892465\n",
      "[28/100] Loss: 0.394282, Acc: 0.893411\n",
      "[28/100] Loss: 0.393105, Acc: 0.893792\n",
      "[28/100] Loss: 0.392563, Acc: 0.894288\n",
      "Finish 28 epoch, Loss: 0.391392, Acc: 0.894617\n",
      "**********\n",
      "epoch 29\n",
      "[29/100] Loss: 0.385872, Acc: 0.897188\n",
      "[29/100] Loss: 0.385943, Acc: 0.896667\n",
      "[29/100] Loss: 0.386312, Acc: 0.896528\n",
      "[29/100] Loss: 0.388374, Acc: 0.895938\n",
      "[29/100] Loss: 0.388807, Acc: 0.895229\n",
      "[29/100] Loss: 0.389511, Acc: 0.894983\n",
      "Finish 29 epoch, Loss: 0.388583, Acc: 0.895283\n",
      "**********\n",
      "epoch 30\n",
      "[30/100] Loss: 0.379749, Acc: 0.897083\n",
      "[30/100] Loss: 0.380836, Acc: 0.897031\n",
      "[30/100] Loss: 0.383007, Acc: 0.897292\n",
      "[30/100] Loss: 0.387421, Acc: 0.895391\n",
      "[30/100] Loss: 0.386764, Acc: 0.895542\n",
      "[30/100] Loss: 0.386447, Acc: 0.895747\n",
      "Finish 30 epoch, Loss: 0.385982, Acc: 0.895650\n",
      "**********\n",
      "epoch 31\n",
      "[31/100] Loss: 0.387423, Acc: 0.893750\n",
      "[31/100] Loss: 0.388322, Acc: 0.894167\n",
      "[31/100] Loss: 0.388462, Acc: 0.893403\n",
      "[31/100] Loss: 0.387755, Acc: 0.894922\n",
      "[31/100] Loss: 0.385757, Acc: 0.895375\n",
      "[31/100] Loss: 0.383632, Acc: 0.896042\n",
      "Finish 31 epoch, Loss: 0.383469, Acc: 0.896117\n",
      "**********\n",
      "epoch 32\n",
      "[32/100] Loss: 0.387998, Acc: 0.896250\n",
      "[32/100] Loss: 0.383575, Acc: 0.897865\n",
      "[32/100] Loss: 0.383816, Acc: 0.897535\n",
      "[32/100] Loss: 0.380628, Acc: 0.898099\n",
      "[32/100] Loss: 0.381192, Acc: 0.896938\n",
      "[32/100] Loss: 0.381131, Acc: 0.896962\n",
      "Finish 32 epoch, Loss: 0.381089, Acc: 0.896800\n",
      "**********\n",
      "epoch 33\n",
      "[33/100] Loss: 0.393934, Acc: 0.893542\n",
      "[33/100] Loss: 0.383397, Acc: 0.896823\n",
      "[33/100] Loss: 0.381991, Acc: 0.896910\n",
      "[33/100] Loss: 0.381790, Acc: 0.896719\n",
      "[33/100] Loss: 0.380473, Acc: 0.896667\n",
      "[33/100] Loss: 0.379017, Acc: 0.897014\n",
      "Finish 33 epoch, Loss: 0.378840, Acc: 0.897200\n",
      "**********\n",
      "epoch 34\n",
      "[34/100] Loss: 0.374879, Acc: 0.895521\n",
      "[34/100] Loss: 0.378098, Acc: 0.895573\n",
      "[34/100] Loss: 0.376691, Acc: 0.896458\n",
      "[34/100] Loss: 0.375869, Acc: 0.897057\n",
      "[34/100] Loss: 0.375471, Acc: 0.897333\n",
      "[34/100] Loss: 0.376961, Acc: 0.897292\n",
      "Finish 34 epoch, Loss: 0.376681, Acc: 0.897717\n",
      "**********\n",
      "epoch 35\n",
      "[35/100] Loss: 0.372898, Acc: 0.902188\n",
      "[35/100] Loss: 0.374132, Acc: 0.899375\n",
      "[35/100] Loss: 0.369812, Acc: 0.900243\n",
      "[35/100] Loss: 0.371899, Acc: 0.898932\n",
      "[35/100] Loss: 0.372289, Acc: 0.899167\n",
      "[35/100] Loss: 0.373385, Acc: 0.898438\n",
      "Finish 35 epoch, Loss: 0.374603, Acc: 0.898117\n",
      "**********\n",
      "epoch 36\n",
      "[36/100] Loss: 0.371407, Acc: 0.900521\n",
      "[36/100] Loss: 0.370004, Acc: 0.901458\n",
      "[36/100] Loss: 0.375329, Acc: 0.898507\n",
      "[36/100] Loss: 0.373822, Acc: 0.899089\n",
      "[36/100] Loss: 0.372564, Acc: 0.899188\n",
      "[36/100] Loss: 0.370947, Acc: 0.899201\n",
      "Finish 36 epoch, Loss: 0.372638, Acc: 0.898700\n",
      "**********\n",
      "epoch 37\n",
      "[37/100] Loss: 0.372949, Acc: 0.895833\n",
      "[37/100] Loss: 0.373957, Acc: 0.897292\n",
      "[37/100] Loss: 0.370591, Acc: 0.897847\n",
      "[37/100] Loss: 0.371822, Acc: 0.898620\n",
      "[37/100] Loss: 0.371339, Acc: 0.898625\n",
      "[37/100] Loss: 0.369875, Acc: 0.899219\n",
      "Finish 37 epoch, Loss: 0.370759, Acc: 0.899050\n",
      "**********\n",
      "epoch 38\n",
      "[38/100] Loss: 0.367754, Acc: 0.899583\n",
      "[38/100] Loss: 0.364786, Acc: 0.900729\n",
      "[38/100] Loss: 0.365680, Acc: 0.900868\n",
      "[38/100] Loss: 0.368717, Acc: 0.899948\n",
      "[38/100] Loss: 0.367524, Acc: 0.900229\n",
      "[38/100] Loss: 0.368801, Acc: 0.899340\n",
      "Finish 38 epoch, Loss: 0.368946, Acc: 0.899367\n",
      "**********\n",
      "epoch 39\n",
      "[39/100] Loss: 0.360181, Acc: 0.903750\n",
      "[39/100] Loss: 0.360917, Acc: 0.903021\n",
      "[39/100] Loss: 0.364525, Acc: 0.901632\n",
      "[39/100] Loss: 0.364430, Acc: 0.900625\n",
      "[39/100] Loss: 0.365496, Acc: 0.899875\n",
      "[39/100] Loss: 0.366070, Acc: 0.899896\n",
      "Finish 39 epoch, Loss: 0.367195, Acc: 0.899767\n",
      "**********\n",
      "epoch 40\n",
      "[40/100] Loss: 0.361863, Acc: 0.901250\n",
      "[40/100] Loss: 0.368163, Acc: 0.899271\n",
      "[40/100] Loss: 0.368985, Acc: 0.899722\n",
      "[40/100] Loss: 0.367379, Acc: 0.900052\n",
      "[40/100] Loss: 0.367418, Acc: 0.900125\n",
      "[40/100] Loss: 0.365376, Acc: 0.900260\n",
      "Finish 40 epoch, Loss: 0.365533, Acc: 0.900150\n",
      "**********\n",
      "epoch 41\n",
      "[41/100] Loss: 0.367508, Acc: 0.898333\n",
      "[41/100] Loss: 0.368130, Acc: 0.899167\n",
      "[41/100] Loss: 0.366559, Acc: 0.899410\n",
      "[41/100] Loss: 0.365143, Acc: 0.899948\n",
      "[41/100] Loss: 0.364861, Acc: 0.900104\n",
      "[41/100] Loss: 0.364821, Acc: 0.900417\n",
      "Finish 41 epoch, Loss: 0.363918, Acc: 0.900483\n",
      "**********\n",
      "epoch 42\n",
      "[42/100] Loss: 0.357578, Acc: 0.901042\n",
      "[42/100] Loss: 0.362693, Acc: 0.900312\n",
      "[42/100] Loss: 0.365751, Acc: 0.900764\n",
      "[42/100] Loss: 0.364733, Acc: 0.900964\n",
      "[42/100] Loss: 0.363497, Acc: 0.900771\n",
      "[42/100] Loss: 0.362712, Acc: 0.900851\n",
      "Finish 42 epoch, Loss: 0.362369, Acc: 0.900850\n",
      "**********\n",
      "epoch 43\n",
      "[43/100] Loss: 0.355080, Acc: 0.901979\n",
      "[43/100] Loss: 0.354125, Acc: 0.902969\n",
      "[43/100] Loss: 0.356796, Acc: 0.902778\n",
      "[43/100] Loss: 0.356705, Acc: 0.902266\n",
      "[43/100] Loss: 0.359756, Acc: 0.901062\n",
      "[43/100] Loss: 0.359953, Acc: 0.901563\n",
      "Finish 43 epoch, Loss: 0.360867, Acc: 0.901250\n",
      "**********\n",
      "epoch 44\n",
      "[44/100] Loss: 0.347933, Acc: 0.904271\n",
      "[44/100] Loss: 0.357503, Acc: 0.901406\n",
      "[44/100] Loss: 0.361874, Acc: 0.900694\n",
      "[44/100] Loss: 0.361288, Acc: 0.901250\n",
      "[44/100] Loss: 0.361559, Acc: 0.901125\n",
      "[44/100] Loss: 0.359511, Acc: 0.901649\n",
      "Finish 44 epoch, Loss: 0.359419, Acc: 0.901633\n",
      "**********\n",
      "epoch 45\n",
      "[45/100] Loss: 0.370301, Acc: 0.901458\n",
      "[45/100] Loss: 0.361975, Acc: 0.903333\n",
      "[45/100] Loss: 0.360361, Acc: 0.902813\n",
      "[45/100] Loss: 0.358856, Acc: 0.902526\n",
      "[45/100] Loss: 0.359003, Acc: 0.901146\n",
      "[45/100] Loss: 0.358307, Acc: 0.901667\n",
      "Finish 45 epoch, Loss: 0.358027, Acc: 0.901783\n",
      "**********\n",
      "epoch 46\n",
      "[46/100] Loss: 0.364704, Acc: 0.899792\n",
      "[46/100] Loss: 0.364380, Acc: 0.898073\n",
      "[46/100] Loss: 0.359628, Acc: 0.900069\n",
      "[46/100] Loss: 0.358457, Acc: 0.900312\n",
      "[46/100] Loss: 0.357167, Acc: 0.901229\n",
      "[46/100] Loss: 0.356663, Acc: 0.902031\n",
      "Finish 46 epoch, Loss: 0.356655, Acc: 0.902250\n",
      "**********\n",
      "epoch 47\n",
      "[47/100] Loss: 0.349276, Acc: 0.906250\n",
      "[47/100] Loss: 0.352694, Acc: 0.904844\n",
      "[47/100] Loss: 0.355959, Acc: 0.903056\n",
      "[47/100] Loss: 0.355664, Acc: 0.902708\n",
      "[47/100] Loss: 0.354334, Acc: 0.902813\n",
      "[47/100] Loss: 0.355426, Acc: 0.902587\n",
      "Finish 47 epoch, Loss: 0.355384, Acc: 0.902500\n",
      "**********\n",
      "epoch 48\n",
      "[48/100] Loss: 0.350031, Acc: 0.903750\n",
      "[48/100] Loss: 0.351564, Acc: 0.904323\n",
      "[48/100] Loss: 0.355988, Acc: 0.901875\n",
      "[48/100] Loss: 0.353912, Acc: 0.902214\n",
      "[48/100] Loss: 0.354814, Acc: 0.901979\n",
      "[48/100] Loss: 0.354763, Acc: 0.902726\n",
      "Finish 48 epoch, Loss: 0.354118, Acc: 0.902683\n",
      "**********\n",
      "epoch 49\n",
      "[49/100] Loss: 0.350652, Acc: 0.905521\n",
      "[49/100] Loss: 0.348584, Acc: 0.905521\n",
      "[49/100] Loss: 0.354133, Acc: 0.902188\n",
      "[49/100] Loss: 0.354022, Acc: 0.901563\n",
      "[49/100] Loss: 0.354237, Acc: 0.902188\n",
      "[49/100] Loss: 0.353151, Acc: 0.902969\n",
      "Finish 49 epoch, Loss: 0.352871, Acc: 0.903183\n",
      "**********\n",
      "epoch 50\n",
      "[50/100] Loss: 0.358043, Acc: 0.904062\n",
      "[50/100] Loss: 0.355169, Acc: 0.903646\n",
      "[50/100] Loss: 0.357386, Acc: 0.903299\n",
      "[50/100] Loss: 0.355452, Acc: 0.902865\n",
      "[50/100] Loss: 0.353479, Acc: 0.902979\n",
      "[50/100] Loss: 0.351184, Acc: 0.903420\n",
      "Finish 50 epoch, Loss: 0.351692, Acc: 0.903250\n",
      "**********\n",
      "epoch 51\n",
      "[51/100] Loss: 0.341930, Acc: 0.905833\n",
      "[51/100] Loss: 0.353885, Acc: 0.902448\n",
      "[51/100] Loss: 0.351004, Acc: 0.902917\n",
      "[51/100] Loss: 0.352427, Acc: 0.902604\n",
      "[51/100] Loss: 0.351930, Acc: 0.902854\n",
      "[51/100] Loss: 0.351260, Acc: 0.903368\n",
      "Finish 51 epoch, Loss: 0.350566, Acc: 0.903500\n",
      "**********\n",
      "epoch 52\n",
      "[52/100] Loss: 0.352531, Acc: 0.902188\n",
      "[52/100] Loss: 0.346785, Acc: 0.903958\n",
      "[52/100] Loss: 0.347395, Acc: 0.903681\n",
      "[52/100] Loss: 0.346219, Acc: 0.904948\n",
      "[52/100] Loss: 0.345470, Acc: 0.904687\n",
      "[52/100] Loss: 0.348523, Acc: 0.904201\n",
      "Finish 52 epoch, Loss: 0.349432, Acc: 0.903900\n",
      "**********\n",
      "epoch 53\n",
      "[53/100] Loss: 0.347822, Acc: 0.907292\n",
      "[53/100] Loss: 0.350615, Acc: 0.905781\n",
      "[53/100] Loss: 0.351257, Acc: 0.904792\n",
      "[53/100] Loss: 0.349944, Acc: 0.904089\n",
      "[53/100] Loss: 0.349626, Acc: 0.903646\n",
      "[53/100] Loss: 0.349375, Acc: 0.903733\n",
      "Finish 53 epoch, Loss: 0.348343, Acc: 0.903767\n",
      "**********\n",
      "epoch 54\n",
      "[54/100] Loss: 0.347846, Acc: 0.902604\n",
      "[54/100] Loss: 0.341356, Acc: 0.905781\n",
      "[54/100] Loss: 0.348321, Acc: 0.903715\n",
      "[54/100] Loss: 0.346067, Acc: 0.905130\n",
      "[54/100] Loss: 0.347355, Acc: 0.904458\n",
      "[54/100] Loss: 0.348321, Acc: 0.903837\n",
      "Finish 54 epoch, Loss: 0.347292, Acc: 0.904250\n",
      "**********\n",
      "epoch 55\n",
      "[55/100] Loss: 0.338138, Acc: 0.907708\n",
      "[55/100] Loss: 0.344652, Acc: 0.905885\n",
      "[55/100] Loss: 0.346039, Acc: 0.904965\n",
      "[55/100] Loss: 0.347462, Acc: 0.904193\n",
      "[55/100] Loss: 0.346308, Acc: 0.904792\n",
      "[55/100] Loss: 0.344829, Acc: 0.904809\n",
      "Finish 55 epoch, Loss: 0.346261, Acc: 0.904500\n",
      "**********\n",
      "epoch 56\n",
      "[56/100] Loss: 0.353732, Acc: 0.903229\n",
      "[56/100] Loss: 0.351578, Acc: 0.903177\n",
      "[56/100] Loss: 0.355710, Acc: 0.901667\n",
      "[56/100] Loss: 0.351429, Acc: 0.902943\n",
      "[56/100] Loss: 0.347596, Acc: 0.904438\n",
      "[56/100] Loss: 0.345115, Acc: 0.904913\n",
      "Finish 56 epoch, Loss: 0.345279, Acc: 0.904850\n",
      "**********\n",
      "epoch 57\n",
      "[57/100] Loss: 0.350718, Acc: 0.900833\n",
      "[57/100] Loss: 0.345379, Acc: 0.903594\n",
      "[57/100] Loss: 0.340322, Acc: 0.904896\n",
      "[57/100] Loss: 0.341915, Acc: 0.904219\n",
      "[57/100] Loss: 0.340899, Acc: 0.904771\n",
      "[57/100] Loss: 0.343201, Acc: 0.905000\n",
      "Finish 57 epoch, Loss: 0.344301, Acc: 0.904883\n",
      "**********\n",
      "epoch 58\n",
      "[58/100] Loss: 0.342710, Acc: 0.905625\n",
      "[58/100] Loss: 0.343021, Acc: 0.905521\n",
      "[58/100] Loss: 0.342825, Acc: 0.904931\n",
      "[58/100] Loss: 0.343584, Acc: 0.904427\n",
      "[58/100] Loss: 0.342976, Acc: 0.904979\n",
      "[58/100] Loss: 0.343872, Acc: 0.904757\n",
      "Finish 58 epoch, Loss: 0.343351, Acc: 0.905050\n",
      "**********\n",
      "epoch 59\n",
      "[59/100] Loss: 0.347757, Acc: 0.902292\n",
      "[59/100] Loss: 0.345354, Acc: 0.904740\n",
      "[59/100] Loss: 0.344726, Acc: 0.904375\n",
      "[59/100] Loss: 0.341564, Acc: 0.905625\n",
      "[59/100] Loss: 0.340196, Acc: 0.906125\n",
      "[59/100] Loss: 0.341946, Acc: 0.905469\n",
      "Finish 59 epoch, Loss: 0.342422, Acc: 0.905333\n",
      "**********\n",
      "epoch 60\n",
      "[60/100] Loss: 0.348175, Acc: 0.904167\n",
      "[60/100] Loss: 0.343956, Acc: 0.905833\n",
      "[60/100] Loss: 0.339495, Acc: 0.908194\n",
      "[60/100] Loss: 0.341509, Acc: 0.906458\n",
      "[60/100] Loss: 0.341418, Acc: 0.906000\n",
      "[60/100] Loss: 0.340734, Acc: 0.905885\n",
      "Finish 60 epoch, Loss: 0.341524, Acc: 0.905567\n",
      "**********\n",
      "epoch 61\n",
      "[61/100] Loss: 0.350624, Acc: 0.904583\n",
      "[61/100] Loss: 0.343360, Acc: 0.906823\n",
      "[61/100] Loss: 0.344054, Acc: 0.905278\n",
      "[61/100] Loss: 0.340701, Acc: 0.905651\n",
      "[61/100] Loss: 0.341405, Acc: 0.905604\n",
      "[61/100] Loss: 0.340543, Acc: 0.905833\n",
      "Finish 61 epoch, Loss: 0.340652, Acc: 0.905633\n",
      "**********\n",
      "epoch 62\n",
      "[62/100] Loss: 0.354523, Acc: 0.900937\n",
      "[62/100] Loss: 0.346669, Acc: 0.904792\n",
      "[62/100] Loss: 0.343658, Acc: 0.905069\n",
      "[62/100] Loss: 0.341429, Acc: 0.904844\n",
      "[62/100] Loss: 0.341528, Acc: 0.905042\n",
      "[62/100] Loss: 0.338337, Acc: 0.906163\n",
      "Finish 62 epoch, Loss: 0.339786, Acc: 0.905850\n",
      "**********\n",
      "epoch 63\n",
      "[63/100] Loss: 0.340927, Acc: 0.905729\n",
      "[63/100] Loss: 0.336008, Acc: 0.907813\n",
      "[63/100] Loss: 0.333419, Acc: 0.908576\n",
      "[63/100] Loss: 0.335990, Acc: 0.907917\n",
      "[63/100] Loss: 0.337339, Acc: 0.907646\n",
      "[63/100] Loss: 0.338240, Acc: 0.906458\n",
      "Finish 63 epoch, Loss: 0.338970, Acc: 0.906100\n",
      "**********\n",
      "epoch 64\n",
      "[64/100] Loss: 0.338818, Acc: 0.905417\n",
      "[64/100] Loss: 0.337907, Acc: 0.906354\n",
      "[64/100] Loss: 0.336978, Acc: 0.906458\n",
      "[64/100] Loss: 0.337897, Acc: 0.906458\n",
      "[64/100] Loss: 0.336722, Acc: 0.906229\n",
      "[64/100] Loss: 0.338307, Acc: 0.905972\n",
      "Finish 64 epoch, Loss: 0.338141, Acc: 0.906100\n",
      "**********\n",
      "epoch 65\n",
      "[65/100] Loss: 0.338079, Acc: 0.904583\n",
      "[65/100] Loss: 0.341446, Acc: 0.904948\n",
      "[65/100] Loss: 0.338412, Acc: 0.906424\n",
      "[65/100] Loss: 0.337193, Acc: 0.906693\n",
      "[65/100] Loss: 0.335023, Acc: 0.907479\n",
      "[65/100] Loss: 0.337453, Acc: 0.906840\n",
      "Finish 65 epoch, Loss: 0.337348, Acc: 0.906683\n",
      "**********\n",
      "epoch 66\n",
      "[66/100] Loss: 0.341337, Acc: 0.905521\n",
      "[66/100] Loss: 0.336206, Acc: 0.905104\n",
      "[66/100] Loss: 0.335894, Acc: 0.906042\n",
      "[66/100] Loss: 0.334542, Acc: 0.906901\n",
      "[66/100] Loss: 0.335968, Acc: 0.906604\n",
      "[66/100] Loss: 0.336796, Acc: 0.906510\n",
      "Finish 66 epoch, Loss: 0.336564, Acc: 0.906600\n",
      "**********\n",
      "epoch 67\n",
      "[67/100] Loss: 0.338660, Acc: 0.907708\n",
      "[67/100] Loss: 0.334945, Acc: 0.907188\n",
      "[67/100] Loss: 0.334019, Acc: 0.907118\n",
      "[67/100] Loss: 0.336199, Acc: 0.906406\n",
      "[67/100] Loss: 0.335300, Acc: 0.906750\n",
      "[67/100] Loss: 0.335521, Acc: 0.907014\n",
      "Finish 67 epoch, Loss: 0.335809, Acc: 0.906833\n",
      "**********\n",
      "epoch 68\n",
      "[68/100] Loss: 0.352000, Acc: 0.902500\n",
      "[68/100] Loss: 0.345067, Acc: 0.904010\n",
      "[68/100] Loss: 0.341367, Acc: 0.905035\n",
      "[68/100] Loss: 0.337491, Acc: 0.905990\n",
      "[68/100] Loss: 0.335267, Acc: 0.906833\n",
      "[68/100] Loss: 0.333781, Acc: 0.907569\n",
      "Finish 68 epoch, Loss: 0.335054, Acc: 0.907150\n",
      "**********\n",
      "epoch 69\n",
      "[69/100] Loss: 0.332590, Acc: 0.909271\n",
      "[69/100] Loss: 0.331446, Acc: 0.908385\n",
      "[69/100] Loss: 0.331670, Acc: 0.908507\n",
      "[69/100] Loss: 0.336407, Acc: 0.907031\n",
      "[69/100] Loss: 0.333740, Acc: 0.908104\n",
      "[69/100] Loss: 0.333115, Acc: 0.908021\n",
      "Finish 69 epoch, Loss: 0.334339, Acc: 0.907400\n",
      "**********\n",
      "epoch 70\n",
      "[70/100] Loss: 0.333763, Acc: 0.908542\n",
      "[70/100] Loss: 0.330818, Acc: 0.908490\n",
      "[70/100] Loss: 0.332834, Acc: 0.908472\n",
      "[70/100] Loss: 0.332251, Acc: 0.908802\n",
      "[70/100] Loss: 0.334437, Acc: 0.907896\n",
      "[70/100] Loss: 0.332967, Acc: 0.907552\n",
      "Finish 70 epoch, Loss: 0.333612, Acc: 0.907300\n",
      "**********\n",
      "epoch 71\n",
      "[71/100] Loss: 0.332280, Acc: 0.907708\n",
      "[71/100] Loss: 0.329083, Acc: 0.909062\n",
      "[71/100] Loss: 0.330439, Acc: 0.908854\n",
      "[71/100] Loss: 0.329724, Acc: 0.908984\n",
      "[71/100] Loss: 0.330009, Acc: 0.908854\n",
      "[71/100] Loss: 0.331805, Acc: 0.907917\n",
      "Finish 71 epoch, Loss: 0.332923, Acc: 0.907650\n",
      "**********\n",
      "epoch 72\n",
      "[72/100] Loss: 0.335856, Acc: 0.909687\n",
      "[72/100] Loss: 0.325487, Acc: 0.909531\n",
      "[72/100] Loss: 0.326964, Acc: 0.909306\n",
      "[72/100] Loss: 0.331298, Acc: 0.908385\n",
      "[72/100] Loss: 0.331911, Acc: 0.907937\n",
      "[72/100] Loss: 0.332188, Acc: 0.908073\n",
      "Finish 72 epoch, Loss: 0.332243, Acc: 0.907867\n",
      "**********\n",
      "epoch 73\n",
      "[73/100] Loss: 0.318580, Acc: 0.912813\n",
      "[73/100] Loss: 0.331437, Acc: 0.908854\n",
      "[73/100] Loss: 0.332780, Acc: 0.908125\n",
      "[73/100] Loss: 0.333087, Acc: 0.907604\n",
      "[73/100] Loss: 0.332079, Acc: 0.908250\n",
      "[73/100] Loss: 0.331908, Acc: 0.907431\n",
      "Finish 73 epoch, Loss: 0.331580, Acc: 0.907883\n",
      "**********\n",
      "epoch 74\n",
      "[74/100] Loss: 0.334638, Acc: 0.906771\n",
      "[74/100] Loss: 0.334215, Acc: 0.905885\n",
      "[74/100] Loss: 0.336362, Acc: 0.906389\n",
      "[74/100] Loss: 0.333363, Acc: 0.907083\n",
      "[74/100] Loss: 0.333367, Acc: 0.907500\n",
      "[74/100] Loss: 0.331906, Acc: 0.907760\n",
      "Finish 74 epoch, Loss: 0.330913, Acc: 0.908183\n",
      "**********\n",
      "epoch 75\n",
      "[75/100] Loss: 0.327960, Acc: 0.912917\n",
      "[75/100] Loss: 0.334457, Acc: 0.909375\n",
      "[75/100] Loss: 0.331568, Acc: 0.908646\n",
      "[75/100] Loss: 0.331109, Acc: 0.908359\n",
      "[75/100] Loss: 0.330669, Acc: 0.908167\n",
      "[75/100] Loss: 0.331497, Acc: 0.908177\n",
      "Finish 75 epoch, Loss: 0.330265, Acc: 0.908433\n",
      "**********\n",
      "epoch 76\n",
      "[76/100] Loss: 0.337428, Acc: 0.906771\n",
      "[76/100] Loss: 0.340598, Acc: 0.905937\n",
      "[76/100] Loss: 0.336425, Acc: 0.907535\n",
      "[76/100] Loss: 0.333582, Acc: 0.908151\n",
      "[76/100] Loss: 0.333070, Acc: 0.907958\n",
      "[76/100] Loss: 0.330397, Acc: 0.908750\n",
      "Finish 76 epoch, Loss: 0.329621, Acc: 0.908783\n",
      "**********\n",
      "epoch 77\n",
      "[77/100] Loss: 0.335787, Acc: 0.907604\n",
      "[77/100] Loss: 0.336453, Acc: 0.907865\n",
      "[77/100] Loss: 0.334538, Acc: 0.907743\n",
      "[77/100] Loss: 0.335003, Acc: 0.906979\n",
      "[77/100] Loss: 0.331835, Acc: 0.907896\n",
      "[77/100] Loss: 0.329494, Acc: 0.908368\n",
      "Finish 77 epoch, Loss: 0.329034, Acc: 0.908517\n",
      "**********\n",
      "epoch 78\n",
      "[78/100] Loss: 0.324125, Acc: 0.910833\n",
      "[78/100] Loss: 0.326028, Acc: 0.910104\n",
      "[78/100] Loss: 0.329669, Acc: 0.907986\n",
      "[78/100] Loss: 0.330758, Acc: 0.907578\n",
      "[78/100] Loss: 0.327525, Acc: 0.908312\n",
      "[78/100] Loss: 0.327815, Acc: 0.908993\n",
      "Finish 78 epoch, Loss: 0.328415, Acc: 0.908867\n",
      "**********\n",
      "epoch 79\n",
      "[79/100] Loss: 0.317909, Acc: 0.912604\n",
      "[79/100] Loss: 0.318407, Acc: 0.910990\n",
      "[79/100] Loss: 0.322685, Acc: 0.910278\n",
      "[79/100] Loss: 0.324707, Acc: 0.909375\n",
      "[79/100] Loss: 0.325999, Acc: 0.909333\n",
      "[79/100] Loss: 0.327248, Acc: 0.909497\n",
      "Finish 79 epoch, Loss: 0.327821, Acc: 0.909033\n",
      "**********\n",
      "epoch 80\n",
      "[80/100] Loss: 0.334974, Acc: 0.905833\n",
      "[80/100] Loss: 0.333246, Acc: 0.906771\n",
      "[80/100] Loss: 0.330085, Acc: 0.908403\n",
      "[80/100] Loss: 0.329177, Acc: 0.908828\n",
      "[80/100] Loss: 0.328797, Acc: 0.909333\n",
      "[80/100] Loss: 0.327464, Acc: 0.909549\n",
      "Finish 80 epoch, Loss: 0.327241, Acc: 0.909550\n",
      "**********\n",
      "epoch 81\n",
      "[81/100] Loss: 0.317080, Acc: 0.911146\n",
      "[81/100] Loss: 0.323053, Acc: 0.909010\n",
      "[81/100] Loss: 0.326929, Acc: 0.908576\n",
      "[81/100] Loss: 0.326782, Acc: 0.909010\n",
      "[81/100] Loss: 0.325453, Acc: 0.910083\n",
      "[81/100] Loss: 0.326574, Acc: 0.909653\n",
      "Finish 81 epoch, Loss: 0.326657, Acc: 0.909633\n",
      "**********\n",
      "epoch 82\n",
      "[82/100] Loss: 0.317883, Acc: 0.913542\n",
      "[82/100] Loss: 0.331823, Acc: 0.909010\n",
      "[82/100] Loss: 0.333830, Acc: 0.907188\n",
      "[82/100] Loss: 0.329496, Acc: 0.908516\n",
      "[82/100] Loss: 0.327414, Acc: 0.909125\n",
      "[82/100] Loss: 0.326778, Acc: 0.909514\n",
      "Finish 82 epoch, Loss: 0.326105, Acc: 0.909783\n",
      "**********\n",
      "epoch 83\n",
      "[83/100] Loss: 0.332793, Acc: 0.907917\n",
      "[83/100] Loss: 0.328237, Acc: 0.911094\n",
      "[83/100] Loss: 0.324401, Acc: 0.912326\n",
      "[83/100] Loss: 0.326209, Acc: 0.910208\n",
      "[83/100] Loss: 0.326370, Acc: 0.910188\n",
      "[83/100] Loss: 0.325972, Acc: 0.910052\n",
      "Finish 83 epoch, Loss: 0.325541, Acc: 0.910017\n",
      "**********\n",
      "epoch 84\n",
      "[84/100] Loss: 0.324384, Acc: 0.909687\n",
      "[84/100] Loss: 0.329577, Acc: 0.907917\n",
      "[84/100] Loss: 0.324861, Acc: 0.909340\n",
      "[84/100] Loss: 0.326217, Acc: 0.910260\n",
      "[84/100] Loss: 0.326825, Acc: 0.909708\n",
      "[84/100] Loss: 0.325444, Acc: 0.910052\n",
      "Finish 84 epoch, Loss: 0.325009, Acc: 0.910050\n",
      "**********\n",
      "epoch 85\n",
      "[85/100] Loss: 0.316324, Acc: 0.913125\n",
      "[85/100] Loss: 0.324325, Acc: 0.910625\n",
      "[85/100] Loss: 0.325516, Acc: 0.909826\n",
      "[85/100] Loss: 0.325474, Acc: 0.909974\n",
      "[85/100] Loss: 0.325492, Acc: 0.910021\n",
      "[85/100] Loss: 0.324520, Acc: 0.910226\n",
      "Finish 85 epoch, Loss: 0.324471, Acc: 0.910167\n",
      "**********\n",
      "epoch 86\n",
      "[86/100] Loss: 0.322570, Acc: 0.910833\n",
      "[86/100] Loss: 0.322966, Acc: 0.911510\n",
      "[86/100] Loss: 0.323891, Acc: 0.910556\n",
      "[86/100] Loss: 0.322348, Acc: 0.910859\n",
      "[86/100] Loss: 0.325061, Acc: 0.910146\n",
      "[86/100] Loss: 0.323859, Acc: 0.910417\n",
      "Finish 86 epoch, Loss: 0.323941, Acc: 0.910250\n",
      "**********\n",
      "epoch 87\n",
      "[87/100] Loss: 0.324029, Acc: 0.913854\n",
      "[87/100] Loss: 0.327191, Acc: 0.910729\n",
      "[87/100] Loss: 0.323608, Acc: 0.910903\n",
      "[87/100] Loss: 0.321537, Acc: 0.911432\n",
      "[87/100] Loss: 0.323069, Acc: 0.911000\n",
      "[87/100] Loss: 0.323267, Acc: 0.910295\n",
      "Finish 87 epoch, Loss: 0.323423, Acc: 0.910283\n",
      "**********\n",
      "epoch 88\n",
      "[88/100] Loss: 0.313105, Acc: 0.914062\n",
      "[88/100] Loss: 0.321171, Acc: 0.910521\n",
      "[88/100] Loss: 0.319312, Acc: 0.910833\n",
      "[88/100] Loss: 0.322807, Acc: 0.910729\n",
      "[88/100] Loss: 0.323595, Acc: 0.910271\n",
      "[88/100] Loss: 0.323512, Acc: 0.910104\n",
      "Finish 88 epoch, Loss: 0.322921, Acc: 0.910433\n",
      "**********\n",
      "epoch 89\n",
      "[89/100] Loss: 0.316571, Acc: 0.913229\n",
      "[89/100] Loss: 0.317061, Acc: 0.912708\n",
      "[89/100] Loss: 0.320339, Acc: 0.911146\n",
      "[89/100] Loss: 0.324190, Acc: 0.910104\n",
      "[89/100] Loss: 0.322329, Acc: 0.910625\n",
      "[89/100] Loss: 0.321821, Acc: 0.910521\n",
      "Finish 89 epoch, Loss: 0.322423, Acc: 0.910483\n",
      "**********\n",
      "epoch 90\n",
      "[90/100] Loss: 0.316566, Acc: 0.913854\n",
      "[90/100] Loss: 0.316761, Acc: 0.913177\n",
      "[90/100] Loss: 0.322485, Acc: 0.911076\n",
      "[90/100] Loss: 0.321870, Acc: 0.910885\n",
      "[90/100] Loss: 0.319526, Acc: 0.911438\n",
      "[90/100] Loss: 0.321659, Acc: 0.910937\n",
      "Finish 90 epoch, Loss: 0.321940, Acc: 0.910667\n",
      "**********\n",
      "epoch 91\n",
      "[91/100] Loss: 0.326438, Acc: 0.911458\n",
      "[91/100] Loss: 0.320153, Acc: 0.911458\n",
      "[91/100] Loss: 0.320462, Acc: 0.912049\n",
      "[91/100] Loss: 0.317623, Acc: 0.912370\n",
      "[91/100] Loss: 0.321728, Acc: 0.910771\n",
      "[91/100] Loss: 0.321611, Acc: 0.910538\n",
      "Finish 91 epoch, Loss: 0.321427, Acc: 0.910650\n",
      "**********\n",
      "epoch 92\n",
      "[92/100] Loss: 0.324939, Acc: 0.910729\n",
      "[92/100] Loss: 0.323935, Acc: 0.909948\n",
      "[92/100] Loss: 0.320756, Acc: 0.910972\n",
      "[92/100] Loss: 0.320213, Acc: 0.911042\n",
      "[92/100] Loss: 0.321424, Acc: 0.911167\n",
      "[92/100] Loss: 0.320468, Acc: 0.911163\n",
      "Finish 92 epoch, Loss: 0.320969, Acc: 0.910983\n",
      "**********\n",
      "epoch 93\n",
      "[93/100] Loss: 0.321319, Acc: 0.910729\n",
      "[93/100] Loss: 0.319042, Acc: 0.911094\n",
      "[93/100] Loss: 0.319846, Acc: 0.912014\n",
      "[93/100] Loss: 0.321752, Acc: 0.911641\n",
      "[93/100] Loss: 0.321877, Acc: 0.910979\n",
      "[93/100] Loss: 0.319995, Acc: 0.911128\n",
      "Finish 93 epoch, Loss: 0.320506, Acc: 0.911083\n",
      "**********\n",
      "epoch 94\n",
      "[94/100] Loss: 0.319308, Acc: 0.909167\n",
      "[94/100] Loss: 0.320593, Acc: 0.909583\n",
      "[94/100] Loss: 0.323628, Acc: 0.909375\n",
      "[94/100] Loss: 0.322536, Acc: 0.909792\n",
      "[94/100] Loss: 0.322957, Acc: 0.910083\n",
      "[94/100] Loss: 0.319740, Acc: 0.911146\n",
      "Finish 94 epoch, Loss: 0.320058, Acc: 0.911083\n",
      "**********\n",
      "epoch 95\n",
      "[95/100] Loss: 0.310362, Acc: 0.915104\n",
      "[95/100] Loss: 0.313901, Acc: 0.913750\n",
      "[95/100] Loss: 0.316722, Acc: 0.912326\n",
      "[95/100] Loss: 0.319532, Acc: 0.911510\n",
      "[95/100] Loss: 0.318643, Acc: 0.911604\n",
      "[95/100] Loss: 0.319849, Acc: 0.911319\n",
      "Finish 95 epoch, Loss: 0.319598, Acc: 0.911300\n",
      "**********\n",
      "epoch 96\n",
      "[96/100] Loss: 0.325663, Acc: 0.905312\n",
      "[96/100] Loss: 0.330573, Acc: 0.906250\n",
      "[96/100] Loss: 0.327495, Acc: 0.908299\n",
      "[96/100] Loss: 0.323590, Acc: 0.908776\n",
      "[96/100] Loss: 0.321646, Acc: 0.910458\n",
      "[96/100] Loss: 0.319968, Acc: 0.911250\n",
      "Finish 96 epoch, Loss: 0.319151, Acc: 0.911483\n",
      "**********\n",
      "epoch 97\n",
      "[97/100] Loss: 0.313922, Acc: 0.917396\n",
      "[97/100] Loss: 0.312697, Acc: 0.916146\n",
      "[97/100] Loss: 0.317217, Acc: 0.913368\n",
      "[97/100] Loss: 0.315960, Acc: 0.913385\n",
      "[97/100] Loss: 0.317124, Acc: 0.912375\n",
      "[97/100] Loss: 0.318729, Acc: 0.911406\n",
      "Finish 97 epoch, Loss: 0.318718, Acc: 0.911483\n",
      "**********\n",
      "epoch 98\n",
      "[98/100] Loss: 0.331884, Acc: 0.906458\n",
      "[98/100] Loss: 0.328169, Acc: 0.910417\n",
      "[98/100] Loss: 0.324464, Acc: 0.910417\n",
      "[98/100] Loss: 0.321582, Acc: 0.910729\n",
      "[98/100] Loss: 0.319138, Acc: 0.910979\n",
      "[98/100] Loss: 0.318456, Acc: 0.911771\n",
      "Finish 98 epoch, Loss: 0.318287, Acc: 0.911700\n",
      "**********\n",
      "epoch 99\n",
      "[99/100] Loss: 0.313685, Acc: 0.911354\n",
      "[99/100] Loss: 0.314880, Acc: 0.912500\n",
      "[99/100] Loss: 0.316846, Acc: 0.911458\n",
      "[99/100] Loss: 0.315967, Acc: 0.911563\n",
      "[99/100] Loss: 0.315184, Acc: 0.912104\n",
      "[99/100] Loss: 0.317295, Acc: 0.911927\n",
      "Finish 99 epoch, Loss: 0.317854, Acc: 0.911683\n",
      "**********\n",
      "epoch 100\n",
      "[100/100] Loss: 0.308975, Acc: 0.916250\n",
      "[100/100] Loss: 0.317080, Acc: 0.912813\n",
      "[100/100] Loss: 0.319079, Acc: 0.911806\n",
      "[100/100] Loss: 0.320230, Acc: 0.910755\n",
      "[100/100] Loss: 0.318622, Acc: 0.911646\n",
      "[100/100] Loss: 0.317829, Acc: 0.911823\n",
      "Finish 100 epoch, Loss: 0.317439, Acc: 0.911867\n",
      "Time:6.7 s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoches):\n",
    "    print('*' * 10)\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    since = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)  # 将图片展开成 28x28\n",
    "        if use_gpu:\n",
    "            img = Variable(img).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "        else:\n",
    "            img = Variable(img)\n",
    "            label = Variable(label)\n",
    "        # 向前传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.data[0] * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        running_acc += num_correct.data[0]\n",
    "        # 向后传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 300 == 0:\n",
    "            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "                epoch + 1, num_epoches, running_loss / (batch_size * i),\n",
    "                running_acc / (batch_size * i)))\n",
    "    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "        epoch + 1, running_loss / (len(train_dataset)), running_acc / (len(\n",
    "            train_dataset))))\n",
    "print('Time:{:.1f} s'.format(time.time() - since))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.305400, Acc: 0.916200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_loss = 0.\n",
    "eval_acc = 0.\n",
    "for data in test_loader:\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    if use_gpu:\n",
    "        img = Variable(img, volatile=True).cuda()\n",
    "        label = Variable(label, volatile=True).cuda()\n",
    "    else:\n",
    "        img = Variable(img, volatile=True)\n",
    "        label = Variable(label, volatile=True)\n",
    "    out = model(img)\n",
    "    loss = criterion(out, label)\n",
    "    eval_loss += loss.data[0] * label.size(0)\n",
    "    _, pred = torch.max(out, 1)\n",
    "    num_correct = (pred == label).sum()\n",
    "    eval_acc += num_correct.data[0]\n",
    "print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "        test_dataset)), eval_acc / (len(test_dataset))))\n",
    "#print('Time:{:.1f} s'.format(time.time() - since))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
